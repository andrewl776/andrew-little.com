blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
library(blogdown)
serve_site()
stop_server()
serve_site()
stop_server()
serve_site()
blogdown::build_site()
stop_server()
serve_site()
stop_server()
blogdown::build_site()
serve_site()
blogdown::build_site()
stop_server()
serve_site()
stop_server()
serve_site()
fpl_data <- FPLdata()
library(FPLdata)
fpl_data <- FPLdata()
fpl_data
fpl_data <- FPLdata()
fpl_data
serve_site()
serve_site()
blogdown::build_site()
serve_site()
stop_server()
serve_site()
list.files("content/posts/readmes/")
paste0("content/posts/readmes/", list.files("content/posts/readmes/"))
blogdown::build_site()
library(blogdown)
serve:site()
serve_site()
blogdown::build_site()
serve_site()
stop_server()
serve_site()
serve_site()
blogdown::build_site()
serve_site()
serve_site()
blogdown::build_site()
serve_site()
blogdown::build_site()
serve_site()
stop_server()
serve_site()
stop_server()
blogdown::build_site()
serve_site()
stop_server()
blogdown::build_site()
serve_site()
stop_server()
blogdown::build_site()
Sys.Date()
blogdown:::preview_site()
stop_server()
blogdown::build_site()
blogdown:::preview_site()
blogdown::build_site()
stop_server()
blogdown::build_site()
blogdown::build_site()
stop_server()
serve_site()
blogdown::build_site()
blogdown::build_site()
serve_site()
stop_server()
serve_site()
stop_server()
serve_site()
library(lubridate)
library(tidyverse)
library(rvest)
library(spotifyr)
library(stringi)
library(glue)
library(progress)
library(tidytext)
library(textdata)
library(wordcloud)
library(wordcloud2)
library(reshape2)
library(topicmodels)
library(furrr)
library(LDAvis)
library(SnowballC)
library(stopwords)
library(parallel)
library(lexicon)
library(sentimentr)
library(magrittr)
library(tidymodels)
library(textrecipes)
library(discrim)
library(lsa)
library(naivebayes)
source("utils.R")
# 1) Scrape chart data ----
start_date <- mdy("12/29/2016")
stop_date <- mdy("09/02/2021")
# Define what dates (and therefore URLs) we will iterate over
dates <- tibble("from" = seq(start_date, stop_date, by = "weeks")) %>%
mutate(from = from + days(1),
"to" = lead(from)) %>%
drop_na() %>%
mutate("url" = paste0("https://spotifycharts.com/regional/global/weekly/",
from, "--", to))
# Iterate over URLs and bind rows together (in parallel)
# Create cluster
cl <- parallel::makeCluster(4)
# Give each core the "dates" object
parallel::clusterExport(
cl,
"dates"
)
# Library in the tidyverse and rvest once in each cluster
parallel::clusterEvalQ(cl, {
library(tidyverse)
library(rvest)
})
# Loop in parallel
chart_data <- parallel::parLapply(cl, dates$url, scrape_chart_data)
# Stop cluster
parallel::stopCluster(cl)
# Let's have a look at how this function works
scrape_chart_data(dates$url[1])
# Bind rows together and only pick out distinct tracks
chart_data <- chart_data %>%
bind_rows() %>%
distinct(track_name, artist, .keep_all = TRUE)
chart_data
# EXERCISE: See slides
# Here is one we made earlier
chart_data <- readr::read_csv("data/output/chart_data.csv.gz")
# 2) Enrich dataset with spotify API ----
# https://developer.spotify.com/documentation/web-api/reference/
# If you're trying to follow along, don't worry about setting up Spotify credentials,
# use the dataset provided.
# IMPORTANT: need to set environment variables below using API credentials
# https://developer.spotify.com/my-applications/#!/applications
# -> use spotify account to log in, create application, credentials will be shown after
#
# Sys.setenv(SPOTIFY_CLIENT_ID = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX')
# Sys.setenv(SPOTIFY_CLIENT_SECRET = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX')
#
# Confirm everything is working with this function:
# get_spotify_access_token()
# We will now enrich the dataset with tracks from specific playlists,
# as opposed to those at the top of the charts
# Search for playlists using keyword
playlists <- search_spotify("rock", type = "playlist", limit = 50)
get_spotify_access_token()
library(blogdown)
build_site()
blogdown::install_hugo("0.89.4")
build_site()
install.packages('gitcreds')
library(gitcreds)
gitcreds_set()
blogdown::check_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
build_site()
blogdown::serve_site()
stop_server()
stop_server()
blogdown::serve_site()
build_site()
build_site()
stop_server()
blogdown::serve_site()
install.packages('dlstats')
dlstats::cran_stats('FPLdata')
x <- dlstats::cran_stats('FPLdata')
x
sum(x$downloads)
x <- dlstats::cran_stats('aRbs')
x
sum(x$downloads)
build_site()
stop_server
stop_server()
serve_site()
stop_server()
build_site()
serve_site()
build_site()
stop_server()
serve_site()
stop_server()
serve_site()
stop_server()
build_site()
serve_site()
stop_server()
build_site()
serve_site()
serve_site()
stop_server()
serve_site()
stop_server()
build_site()
serve_site()
blogdown::serve_site()
library(bookdown)
check_site()
library(blogdown)
check_site()
build_site()
1+2
blogdown:::preview_site()
install.packages('blogdown')
library(blogdown)
build_site()
serve_site()
serve_site()
build_site()
serve_site()
blogdown::stop_server()
serve_site()
blogdown::build_site()
blogdown::build_site()
serve_site()
serve_site()
blogdown::build_site(build_rmd = TRUE)
install.packages('FPLdata')
blogdown::build_site(build_rmd = TRUE)
serve_site()
blogdown::build_site(build_rmd = TRUE)
blogdown::build_site(build_rmd = TRUE)
serve_site()
serve_site()
blogdown::config_netlify()
build_site()
library(blogdown)
build_site()
serv_site()
serve_site()
blogdown:::preview_site()
build_site()
library(blogdown)
stop_server()
build_site()
serve_site()
build_site()
build_site()
serve_site()
stop_server()
serve_site()
stop_server()
build_site()
serve_site()
serve_site()
build_site()
serve_site()
stop_server()
build_site()
stop_server()
serve_site()
stop_server()
stop_server()
build_site()
serve_site()
stop_server()
build_site()
serve_site()
knitr::opts_chunk$set(echo = TRUE)
knitr::include_graphics('../../../static/process_diagram.jpeg')
knitr::include_graphics('../../static/process_diagram.jpeg')
knitr::include_graphics('static/process_diagram.jpeg')
knitr::include_graphics('static/process_diagram.jpeg')
knitr::include_graphics('../../../static/img/process_diagram.jpeg')
stop_server()
build_site()
serve_site()
build_site()
serve_site()
knitr::include_graphics('../../../static/img/process_diagram.png')
knitr::include_graphics('../../../static/img/process_diagram.png')
stop_server()
build_site()
serve_site()
build_site()
serve_site()
serve_site()
stop_server()
serve_site()
serve_site()
stop_server()
build_site()
serve_site()
serve_site()
stop_server()
build_site()
stop_server()
serve_site()
serve_site()
stop_server()
build_site()
serve_site()
stop_server()
serve_site()
serve_site()
build_site()
serve_site()
stop_server()
serve_site()
stop_server()
build_site()
serve_site()
stop_server()
build_site()
serve_site()
stop_server()
build_site()
serve_site()
serve_site()
library(blogdown)
serve_site()
blogdown::stop_server()
build_site()
serve_site()
blogdown::stop_server()
build_site()
serve_site()
blogdown::stop_server()
build_site()
serve_site()
serve_site()
build_site()
serve_site()
build_site()
serve_site()
serve_site()
serve_site()
build_site()
build_site()
serve_site()
build_site()
build_site()
build_site()
serve_site()
blogdown::stop_server()
build_site()
serve_site()
build_site()
serve_site()
build_site()
serve_site()
build_site()
blogdown::stop_server()
serve_site()
blogdown::stop_server()
build_site()
serve_site()
blogdown::stop_server()
build_site()
serve_site()
build_site()
serve_site()
blogdown::stop_server()
serve_site()
blogdown::stop_server()
build_site()
serve_site()
build_site()
build_site()
serve_site()
serve_site()
build_site()
build_site()
serve_site()
build_site()
serve_site()
readLines('./FPLdata.Rmd')
readLines('./FPLdata.html')
readLines('./FPLdata.html')
readLines('./FPLdata.html')
library(dplyr)
readLines('./FPLdata.Rmd') %>% tidytext::unnest_tokens()
library(dplyr)
readLines('./FPLdata.Rmd') %>% tibble() %>% tidytext::unnest_tokens()
readLines('./FPLdata.Rmd') %>% tibble()
library(dplyr)
readLines('./FPLdata.Rmd') %>% tibble('x' = .)
library(dplyr)
readLines('./FPLdata.Rmd') %>% tibble('x' = .) %>%
tidytext::unnest_tokens('x')
library(dplyr)
readLines('./FPLdata.Rmd') %>% tibble('x' = .)
library(dplyr)
readLines('./FPLdata.Rmd') %>% tibble('x' = .) %>%
tidytext::unnest_tokens('x')
readLines('./FPLdata.Rmd') %>% tibble('x' = .)
readLines('./content/posts/FPLdata/FPLdata.Rmd') %>% tibble('x' = .)
readLines('./content/posts/FPLdata/FPLdata.Rmd') %>% tibble('x' = .) %>% tidytext::unnest_tokens()
readLines('./content/posts/FPLdata/FPLdata.Rmd') %>% tibble('x' = .) %>% tidytext::unnest_tokens('x')
readLines('./content/posts/FPLdata/FPLdata.Rmd') %>% tibble('x' = .) %>% tidytext::unnest_tokens('x')
readLines('./content/posts/FPLdata/FPLdata.Rmd') %>% tibble('x' = .)[, 1:10] %>% tidytext::unnest_tokens('x')
readLines('./content/posts/FPLdata/FPLdata.Rmd') %>% tibble('x' = .)[1:10] %>% tidytext::unnest_tokens('x')
readLines('./content/posts/FPLdata/FPLdata.Rmd') %>% tibble('x' = .)[1:10, ] %>% tidytext::unnest_tokens('x')
readLines('./content/posts/FPLdata/FPLdata.Rmd') %>% tibble('x' = .)
tibble('x' = c('hi', 'there')) %>% tidytext::unnest_tokens()
tibble('x' = c('hi', 'there')) %>% tidytext::unnest_tokens('x')
tibble('x' = c('hi', 'there')) %>% tidytext::unnest_tokens('x', 'x')
library(dplyr)
readLines('./FPLdata.Rmd') %>% tibble('x' = .) %>%
tidytext::unnest_tokens('x', 'words')
library(dplyr)
readLines('./FPLdata.Rmd') %>% tibble('x' = .) %>%
tidytext::unnest_tokens('words', 'x')
library(dplyr)
readLines('./FPLdata.Rmd') %>% tibble('x' = .) %>%
tidytext::unnest_tokens('words', 'x') %>%
nrow() %>% (./200)
library(dplyr)
readLines('./FPLdata.Rmd') %>% tibble('x' = .) %>%
tidytext::unnest_tokens('words', 'x') %>%
nrow() %>% (.x/200)
library(dplyr)
readLines('./FPLdata.Rmd') %>% tibble('x' = .) %>%
tidytext::unnest_tokens('words', 'x') %>%
nrow() %>% function(s) {s/200)}
library(dplyr)
readLines('./FPLdata.Rmd') %>% tibble('x' = .) %>%
tidytext::unnest_tokens('words', 'x') %>%
nrow() %>% function(s) {s/200}
library(dplyr)
readLines('./FPLdata.Rmd') %>% tibble('x' = .) %>%
tidytext::unnest_tokens('words', 'x') %>%
nrow() %>% function() {./200}
library(dplyr)
readLines('./FPLdata.Rmd') %>% tibble('x' = .) %>%
tidytext::unnest_tokens('words', 'x') %>%
nrow() %>% function(s) {s/200} (.)
library(dplyr)
readLines('./FPLdata.Rmd') %>% tibble('x' = .) %>%
tidytext::unnest_tokens('words', 'x') %>%
nrow() %>% (./200)
library(dplyr)
readLines('./FPLdata.Rmd') %>% tibble('x' = .) %>%
tidytext::unnest_tokens('words', 'x') %>%
nrow() %>% function(s) s/200
library(dplyr)
readLines('./FPLdata.Rmd') %>% tibble('x' = .) %>%
tidytext::unnest_tokens('words', 'x') %>%
nrow() %>% function(s) {s/200}
library(dplyr)
readLines('./FPLdata.Rmd') %>% tibble('x' = .) %>%
tidytext::unnest_tokens('words', 'x') %>%
nrow() %>% (function(s) {s/200})
library(dplyr)
readLines('./FPLdata.Rmd') %>% tibble('x' = .) %>%
tidytext::unnest_tokens('words', 'x') %>%
nrow() %>% (function(s) s/200)
library(dplyr)
readLines('./FPLdata.Rmd') %>% tibble('x' = .) %>%
tidytext::unnest_tokens('words', 'x') %>%
nrow() %>% (function(s) s/200) %>% ceil()
library(dplyr)
readLines('./FPLdata.Rmd') %>% tibble('x' = .) %>%
tidytext::unnest_tokens('words', 'x') %>%
nrow() %>% (function(s) s/200) %>% ceiling()
build_site()
serve_site()
stop_server()
serve_site()
stop_server()
build_site()
serve_site()
stop_server()
build_site()
stop_server()
build_site()
serve_site()
build_site()
serve_site()
build_site()
serve_site()
build_site()
serve_site()
stop_server()
serve_site()
build_site()
serve_site()
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
mins <- readLines(knitr::current_input()) %>% tibble('x' = .) %>%
tidytext::unnest_tokens('words', 'x') %>%
nrow() %>%
(function(s) s/200) %>% ceiling()
library(dplyr)
mins <- readLines(knitr::current_input()) %>% tibble('x' = .) %>%
tidytext::unnest_tokens('words', 'x') %>%
nrow() %>%
(function(s) s/200) %>% ceiling()
current_input()
library(dplyr)
mins <- readLines(knitr::current_input()) %>% tibble('x' = .) %>%
tidytext::unnest_tokens('words', 'x') %>%
nrow() %>%
(function(s) s/200) %>% ceiling()
